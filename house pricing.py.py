# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yD264-DAoG45lmaOvFh4GR2XnwzNV3is
"""

pip install numpy pandas scikit-learn matplotlib seaborn joblib streamlit shap xgboost tqdm

# Step 1: Load the California Housing dataset
from sklearn.datasets import fetch_california_housing
import pandas as pd

# Load data
california = fetch_california_housing(as_frame=True)
df = california.frame

# Show first 5 rows
df.head()

import matplotlib.pyplot as plt
import seaborn as sns

# Check missing values
print(df.isnull().sum())

# Plot distributions
df.hist(bins=30, figsize=(15,10))
plt.show()

# Correlation matrix
plt.figure(figsize=(12,8))
sns.heatmap(df.corr(), annot=True, fmt=".2f", cmap="coolwarm")
plt.show()

# Check target skew
sns.histplot(df['MedHouseVal'], kde=True)
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# Split features and target
X = df.drop('MedHouseVal', axis=1)
y = df['MedHouseVal']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Numeric features
numeric_features = X.columns.tolist()

# Preprocessing pipeline for numeric features
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())  # Standardize features
])

preprocessor = ColumnTransformer(transformers=[
    ('num', numeric_transformer, numeric_features)
])

# Optional Feature Engineering Example
# Let's create 'RoomsPerHousehold' and 'PopulationPerHousehold'
import numpy as np

X_train['RoomsPerHousehold'] = X_train['AveRooms'] / X_train['HouseAge']
X_train['PopulationPerHousehold'] = X_train['Population'] / (X_train['HouseAge'] + 1)  # avoid div by 0

X_test['RoomsPerHousehold'] = X_test['AveRooms'] / X_test['HouseAge']
X_test['PopulationPerHousehold'] = X_test['Population'] / (X_test['HouseAge'] + 1)

# ===============================
# STEP 1: Import Libraries & Load Data
# ===============================
import pandas as pd
import numpy as np
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler, FunctionTransformer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Load California Housing dataset
california = fetch_california_housing(as_frame=True)
df = california.frame

# Features & target
X = df.drop('MedHouseVal', axis=1)
y = df['MedHouseVal']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# ===============================
# STEP 2: Feature Engineering Function
# ===============================
def add_features(X):
    X = X.copy()
    # Example features
    X['RoomsPerHousehold'] = X['AveRooms'] / (X['HouseAge'] + 1)
    X['PopulationPerHousehold'] = X['Population'] / (X['HouseAge'] + 1)
    return X

feature_engineering = FunctionTransformer(add_features)


# ===============================
# STEP 3: Preprocessing
# ===============================
original_features = X.columns.tolist()  # only original features for scaling

numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

preprocessor = ColumnTransformer(transformers=[
    ('num', numeric_transformer, original_features)
])


# ===============================
# STEP 4: Pipelines for Models
# ===============================

# 1. Linear Regression
lr_pipeline = Pipeline(steps=[
    ('feature_engineering', feature_engineering),
    ('preprocessor', preprocessor),
    ('regressor', LinearRegression())
])

# 2. Ridge Regression with GridSearch
ridge_pipeline = Pipeline(steps=[
    ('feature_engineering', feature_engineering),
    ('preprocessor', preprocessor),
    ('regressor', Ridge())
])

ridge_params = {'regressor__alpha': [0.1, 1.0, 10.0, 50.0]}
ridge_search = GridSearchCV(ridge_pipeline, ridge_params, cv=5, scoring='neg_mean_squared_error')

# 3. Lasso Regression with GridSearch
lasso_pipeline = Pipeline(steps=[
    ('feature_engineering', feature_engineering),
    ('preprocessor', preprocessor),
    ('regressor', Lasso(max_iter=10000))
])

lasso_params = {'regressor__alpha': [0.001, 0.01, 0.1, 1.0]}
lasso_search = GridSearchCV(lasso_pipeline, lasso_params, cv=5, scoring='neg_mean_squared_error')


# ===============================
# STEP 5: Fit & Evaluate Models
# ===============================
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    print("MAE:", mean_absolute_error(y_test, y_pred))
    print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
    print("R2:", r2_score(y_test, y_pred))
    print("-"*40)

print("=== Linear Regression ===")
lr_pipeline.fit(X_train, y_train)
evaluate_model(lr_pipeline, X_test, y_test)

print("=== Ridge Regression ===")
ridge_search.fit(X_train, y_train)
print("Best Ridge alpha:", ridge_search.best_params_)
evaluate_model(ridge_search.best_estimator_, X_test, y_test)

print("=== Lasso Regression ===")
lasso_search.fit(X_train, y_train)
print("Best Lasso alpha:", lasso_search.best_params_)
evaluate_model(lasso_search.best_estimator_, X_test, y_test)

import joblib

# Choose the best model (replace with your preferred one)
best_model = ridge_search.best_estimator_  # for example

# Save the model
joblib.dump(best_model, 'best_housing_model.pkl')
print("Model saved as 'best_housing_model.pkl'")

import streamlit as st
import pandas as pd
import joblib

# Load the saved model
model = joblib.load('best_housing_model.pkl')

st.title("California Housing Price Predictor")
st.write("Enter the details of the house:")

# Input fields for house features
MedInc = st.number_input("Median Income (MedInc)", min_value=0.0, value=3.0)
HouseAge = st.number_input("House Age (HouseAge)", min_value=0.0, value=20.0)
AveRooms = st.number_input("Average Rooms (AveRooms)", min_value=0.0, value=5.0)
AveBedrms = st.number_input("Average Bedrooms (AveBedrms)", min_value=0.0, value=1.0)
Population = st.number_input("Population", min_value=0.0, value=1000.0)
AveOccup = st.number_input("Average Occupancy (AveOccup)", min_value=0.0, value=3.0)
Latitude = st.number_input("Latitude", min_value=-90.0, max_value=90.0, value=34.0)
Longitude = st.number_input("Longitude", min_value=-180.0, max_value=180.0, value=-118.0)

# Prepare the input dataframe
input_df = pd.DataFrame({
    'MedInc': [MedInc],
    'HouseAge': [HouseAge],
    'AveRooms': [AveRooms],
    'AveBedrms': [AveBedrms],
    'Population': [Population],
    'AveOccup': [AveOccup],
    'Latitude': [Latitude],
    'Longitude': [Longitude]
})

# Predict button
if st.button("Predict"):
    prediction = model.predict(input_df)
    st.success(f"Predicted Median House Value: ${prediction[0]*100000:.2f}")

import shap

explainer = shap.Explainer(model['regressor'], model['preprocessor'].transform(X_train))
shap_values = explainer(model['preprocessor'].transform(input_df))
st.write(shap.plots.waterfall(shap_values[0]))

# Save the app as app.py
streamlit_code = """
import streamlit as st
import pandas as pd
import joblib

model = joblib.load('best_housing_model.pkl')

st.title("California Housing Price Predictor")
st.write("Enter the details of the house:")

MedInc = st.number_input("Median Income (MedInc)", min_value=0.0, value=3.0)
HouseAge = st.number_input("House Age (HouseAge)", min_value=0.0, value=20.0)
AveRooms = st.number_input("Average Rooms (AveRooms)", min_value=0.0, value=5.0)
AveBedrms = st.number_input("Average Bedrooms (AveBedrms)", min_value=0.0, value=1.0)
Population = st.number_input("Population", min_value=0.0, value=1000.0)
AveOccup = st.number_input("Average Occupancy (AveOccup)", min_value=0.0, value=3.0)
Latitude = st.number_input("Latitude", min_value=-90.0, max_value=90.0, value=34.0)
Longitude = st.number_input("Longitude", min_value=-180.0, max_value=180.0, value=-118.0)

input_df = pd.DataFrame({
    'MedInc': [MedInc],
    'HouseAge': [HouseAge],
    'AveRooms': [AveRooms],
    'AveBedrms': [AveBedrms],
    'Population': [Population],
    'AveOccup': [AveOccup],
    'Latitude': [Latitude],
    'Longitude': [Longitude]
})

if st.button("Predict"):
    prediction = model.predict(input_df)
    st.success(f"Predicted Median House Value: ${prediction[0]*100000:.2f}")
"""

with open("app.py", "w") as f:
    f.write(streamlit_code)

print("Streamlit app saved as 'app.py'")

!kill -9 $(lsof -t -i:8501) 2>/dev/null

!nohup streamlit run app.py --server.port 8501 --server.address 0.0.0.0 >/dev/null 2>&1 &

